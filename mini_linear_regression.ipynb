{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mini_linear_regression.ipynb",
      "provenance": [],
      "mount_file_id": "1sxUt7Z1A0M4UJazs8WXQlQGIaYhIW4NX",
      "authorship_tag": "ABX9TyNRW0jfh1xZhbAqsEx3/8QL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nick09k/AWP-Python-/blob/master/mini_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5neISOVsIv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fUxxvxnsysG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/smartknower/Admission_Predict.csv')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQdGMTPcs2xC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0e88e13d-bead-4761-917a-e7f91b414546"
      },
      "source": [
        "\n",
        "df.columns"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
              "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYXvx7i3s33l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "6c4d2fc1-47db-47ba-a7fd-93f6afb79037"
      },
      "source": [
        "df.drop(['University Rating'], axis = 1) "
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>396</td>\n",
              "      <td>324</td>\n",
              "      <td>110</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.04</td>\n",
              "      <td>1</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>397</td>\n",
              "      <td>325</td>\n",
              "      <td>107</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>398</td>\n",
              "      <td>330</td>\n",
              "      <td>116</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>399</td>\n",
              "      <td>312</td>\n",
              "      <td>103</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>400</td>\n",
              "      <td>333</td>\n",
              "      <td>117</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.66</td>\n",
              "      <td>1</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Serial No.  GRE Score  TOEFL Score  ...  CGPA  Research  Chance of Admit \n",
              "0             1        337          118  ...  9.65         1              0.92\n",
              "1             2        324          107  ...  8.87         1              0.76\n",
              "2             3        316          104  ...  8.00         1              0.72\n",
              "3             4        322          110  ...  8.67         1              0.80\n",
              "4             5        314          103  ...  8.21         0              0.65\n",
              "..          ...        ...          ...  ...   ...       ...               ...\n",
              "395         396        324          110  ...  9.04         1              0.82\n",
              "396         397        325          107  ...  9.11         1              0.84\n",
              "397         398        330          116  ...  9.45         1              0.91\n",
              "398         399        312          103  ...  8.78         0              0.67\n",
              "399         400        333          117  ...  9.66         1              0.95\n",
              "\n",
              "[400 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFwrPJRAtW07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x =df.iloc[:,0:8].values\n",
        "y = df.iloc[:,8].values"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-piT03yXtjeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "e1fbcad2-bbfa-4ee3-d217-c306d1f86955"
      },
      "source": [
        "x"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.  , 337.  , 118.  , ...,   4.5 ,   9.65,   1.  ],\n",
              "       [  2.  , 324.  , 107.  , ...,   4.5 ,   8.87,   1.  ],\n",
              "       [  3.  , 316.  , 104.  , ...,   3.5 ,   8.  ,   1.  ],\n",
              "       ...,\n",
              "       [398.  , 330.  , 116.  , ...,   4.5 ,   9.45,   1.  ],\n",
              "       [399.  , 312.  , 103.  , ...,   4.  ,   8.78,   0.  ],\n",
              "       [400.  , 333.  , 117.  , ...,   4.  ,   9.66,   1.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb5Zh3ufwz-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = x[0:320]\n",
        "train_Y = y[0:320]\n",
        "\n",
        "test_X = x[321:399]\n",
        "test_Y = y[321:399]\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfrVjyiVxOkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "60df514d-f3af-4a9d-96cf-ff6d1455d4e8"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(train_X,train_Y)\n",
        "y_pred = model.predict(test_X)\n",
        "y_pred"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7671319 , 0.71156226, 0.62847333, 0.68192919, 0.88251731,\n",
              "       0.59446697, 0.56038562, 0.82953687, 0.53737955, 0.80484504,\n",
              "       0.65443455, 0.68499277, 0.77393713, 0.78822906, 0.88744447,\n",
              "       0.75696465, 0.98463511, 0.83919007, 0.83192248, 0.73646555,\n",
              "       0.81710776, 0.68280552, 0.65703352, 0.50130295, 0.54919597,\n",
              "       0.55249791, 0.4655987 , 0.50522874, 0.66052865, 0.74735114,\n",
              "       0.83522076, 0.65827749, 0.63331344, 0.56921879, 0.69667501,\n",
              "       0.83333582, 0.65220146, 0.60256486, 0.68705162, 0.83987502,\n",
              "       0.9442013 , 0.97210294, 0.67212698, 0.79242163, 0.88098501,\n",
              "       0.77637878, 0.56066642, 0.53503307, 0.62443319, 0.65828215,\n",
              "       0.8493362 , 0.98089584, 0.77818789, 0.62375638, 0.58709027,\n",
              "       0.51910032, 0.51950353, 0.56106398, 0.68771096, 0.8171684 ,\n",
              "       0.78684413, 0.88232971, 0.66913273, 1.00742246, 1.03137547,\n",
              "       0.63803008, 0.67726552, 0.55993183, 0.7920088 , 0.66941642,\n",
              "       0.75643932, 0.88141145, 0.74231863, 0.90690241, 0.85147574,\n",
              "       0.85106932, 0.95947426, 0.76910099])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WmA0DfQxmnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "42ef6bf6-bc97-4a01-95e9-29671dfc7597"
      },
      "source": [
        "test_Y "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73, 0.72, 0.62, 0.67, 0.81, 0.63, 0.69, 0.8 , 0.43, 0.8 , 0.73,\n",
              "       0.75, 0.71, 0.73, 0.83, 0.72, 0.94, 0.81, 0.81, 0.75, 0.79, 0.58,\n",
              "       0.59, 0.47, 0.49, 0.47, 0.42, 0.57, 0.62, 0.74, 0.73, 0.64, 0.63,\n",
              "       0.59, 0.73, 0.79, 0.68, 0.7 , 0.81, 0.85, 0.93, 0.91, 0.69, 0.77,\n",
              "       0.86, 0.74, 0.57, 0.51, 0.67, 0.72, 0.89, 0.95, 0.79, 0.39, 0.38,\n",
              "       0.34, 0.47, 0.56, 0.71, 0.78, 0.73, 0.82, 0.62, 0.96, 0.96, 0.46,\n",
              "       0.53, 0.49, 0.76, 0.64, 0.71, 0.84, 0.77, 0.89, 0.82, 0.84, 0.91,\n",
              "       0.67])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FodQ_TVzxsw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b02fdd0b-298b-42a4-e1b3-e6ba393894cd"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.mean_squared_error(test_Y,y_pred)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004918576101308849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRcBFFgQx4Ff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0ae62ca-a88d-4a73-c4ee-c847e254db26"
      },
      "source": [
        "metrics.r2_score(test_Y,y_pred)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7755907307447031"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhkBTWDRx9yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxCvtzanyzHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 50)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI9rI6hcRPwC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "fccfa174-3400-4d4b-d0c5-7a95436aa5e1"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.59, 0.94, 0.79, 0.64, 0.54, 0.73, 0.72, 0.84, 0.78, 0.74, 0.82,\n",
              "       0.72, 0.76, 0.77, 0.54, 0.93, 0.72, 0.64, 0.66, 0.62, 0.56, 0.71,\n",
              "       0.7 , 0.61, 0.38, 0.82, 0.48, 0.65, 0.57, 0.62, 0.7 , 0.94, 0.96,\n",
              "       0.64, 0.49, 0.96, 0.93, 0.93, 0.92, 0.52, 0.8 , 0.94, 0.67, 0.52,\n",
              "       0.63, 0.76, 0.73, 0.91, 0.76, 0.92, 0.9 , 0.89, 0.94, 0.58, 0.67,\n",
              "       0.71, 0.72, 0.39, 0.95, 0.74, 0.73, 0.78, 0.94, 0.58, 0.84, 0.7 ,\n",
              "       0.71, 0.65, 0.8 , 0.92, 0.72, 0.78, 0.8 , 0.61, 0.68, 0.97, 0.52,\n",
              "       0.85, 0.95, 0.77, 0.93, 0.71, 0.69, 0.58, 0.75, 0.64, 0.34, 0.71,\n",
              "       0.69, 0.71, 0.86, 0.64, 0.48, 0.64, 0.79, 0.46, 0.79, 0.86, 0.91,\n",
              "       0.53, 0.91, 0.73, 0.7 , 0.87, 0.58, 0.85, 0.57, 0.68, 0.84, 0.9 ,\n",
              "       0.42, 0.89, 0.88, 0.54, 0.78, 0.71, 0.79, 0.73, 0.63, 0.7 , 0.57,\n",
              "       0.72, 0.49, 0.7 , 0.59, 0.94, 0.76, 0.65, 0.52, 0.93, 0.46, 0.61,\n",
              "       0.59, 0.63, 0.65, 0.95, 0.72, 0.8 , 0.83, 0.62, 0.89, 0.74, 0.78,\n",
              "       0.81, 0.74, 0.49, 0.92, 0.68, 0.47, 0.62, 0.78, 0.94, 0.78, 0.67,\n",
              "       0.63, 0.6 , 0.5 , 0.36, 0.52, 0.85, 0.46, 0.64, 0.65, 0.47, 0.81,\n",
              "       0.45, 0.61, 0.72, 0.95, 0.64, 0.76, 0.71, 0.84, 0.7 , 0.77, 0.62,\n",
              "       0.68, 0.77, 0.73, 0.42, 0.71, 0.65, 0.9 , 0.69, 0.68, 0.73, 0.46,\n",
              "       0.9 , 0.97, 0.79, 0.44, 0.56, 0.89, 0.67, 0.92, 0.67, 0.43, 0.75,\n",
              "       0.65, 0.44, 0.7 , 0.62, 0.47, 0.81, 0.73, 0.7 , 0.34, 0.73, 0.89,\n",
              "       0.78, 0.82, 0.64, 0.69, 0.93, 0.71, 0.88, 0.82, 0.88, 0.66, 0.86,\n",
              "       0.47, 0.84, 0.84, 0.71, 0.64, 0.72, 0.54, 0.87, 0.73, 0.86, 0.7 ,\n",
              "       0.56, 0.96, 0.78, 0.78, 0.81, 0.36, 0.75, 0.44, 0.92, 0.61, 0.72,\n",
              "       0.67, 0.62, 0.72, 0.48, 0.76, 0.69, 0.46, 0.96, 0.83, 0.75, 0.75,\n",
              "       0.87, 0.79, 0.78, 0.89, 0.71, 0.89, 0.84, 0.8 , 0.38, 0.57, 0.68,\n",
              "       0.57, 0.96, 0.74, 0.42, 0.77, 0.79, 0.86, 0.66, 0.89, 0.82, 0.94,\n",
              "       0.71, 0.79, 0.68, 0.82, 0.9 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqP7D1s8RV-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "5cc7cf97-80ea-4613-f8a1-301665bf7aa9"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Mean Squared Error \n",
        "metrics.mean_squared_error(y_test,y_pred)\n",
        "# Accuracy Score\n",
        "\n",
        "metrics.r2_score(y_test,y_pred)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-bb1fb9c3e932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Mean Squared Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Accuracy Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 252\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [120, 78]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrxRNg5SyW2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}